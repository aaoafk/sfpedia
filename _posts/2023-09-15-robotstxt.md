---
title:      "robots.txt"
date:       2023-09-15T14:50:23-04:00
tags:       ["scraping", "web"]
identifier: "20230915T145023"
---

A `robots.txt` file tells search engine crawlers which URLs the crawler
can access on your site. This is used mainly to avoid overloading your
site with requests; it is not a mechanism for keeping a web page out
of Google. To keep a web page out of Google, block indexing with
`noindex`.

`robots.txt` files consists of rules that follow a certain syntax
defined here: [Link to `robots.txt` syntax](https://en.wikipedia.org/wiki/Robots_exclusion_standard#Examples) 

